[Meditation play]
[Hyper log log]

There are some algorithms which when I read, I am like, wow: I could have
never figured it out myself without some revelation or a flash of insight
from the heavens. Hyperloglog is one such algorithm.

In this video, my aim is to provide you that initial insight, and then lead
you through the how this amazing algorithm works.

So let's get started.

Suppose we have a sequence of some elements and we want to count how many some 
elements are there in the list. That's a straight forward problem. We just 
iterate through the list, incrementing a counter as we iterate.

Now we modify the problem slightly. Say, we want to count the number of distinct
elements in the sequence.

One way to achieve this would be to again, iterate throught the elements, but,
at each step, check back with the previous elements if the given element has
occurred earlier. This would lead to an essential a complete scan of the sequence
for each element, which is very bad
when dealing with a very large sequences consisting of millions or billions
of data points.

Another way to would be to store the set of distinct elements as we iterate
through the array. As we process a given element, we check in our store if
the element has been seen before. Using efficient data structures for the
element store, we can check for membership, in O(1) time. This ensures a
constant time processing per element, but the element store will store all
the distinct elements, and that too can get very large when there are millions
of distinct elemnets in the sequence.

Now, what if I tell you that I don't need the exact count of distinct elements,
but I am fine with an approximation. For instance, if 1,839,404 distinct users
accessed my website, I am fine with the algorithm returns me an answer of 1.8M,
or even 1.75M or 1.85M.

Given this relaxation, can you come up with an algorithm which takes constant
amount of time per element and uses constant amount of memory as well. That
sounds almost magical, but it is true.

